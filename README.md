# BlueDot AI Safety Fundamentals Alignment Course Project

This project was completed for the summer 2024 cohort of the [BlueDot AI Safety Fundamentals](https://aisafetyfundamentals.com) [Alignment Course](https://course.aisafetyfundamentals.com/alignment). 

## Introduction to Mechanistic Interpretability

For my project, I followed Neel Nanda's [walkthrough](https://www.neelnanda.io/mechanistic-interpretability/modular-addition-walkthrough) of his paper "[Progress Measures for Grokking via Mechanistic Interpretability](https://arxiv.org/pdf/2301.05217)"[^1]


[^1]: N. Nanda, L. Chan, T. Lieberum, J. Smith, and J. Steinhardt, ‘Progress measures for grokking via mechanistic interpretability’. arXiv, Oct. 19, 2023. doi: 10.48550/arXiv.2301.05217.
