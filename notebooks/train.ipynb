{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjkQ2NjLwDj7B5wkfMRzmF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanRaines/bluedot-intro-to-mech-interp/blob/main/notebooks/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "RKHeZXBOEp1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Poetry fro dependency management\n",
        "%%capture\n",
        "!curl -sSL https://install.python-poetry.org | python3 -\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1a2K9_wuDa_P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "%%capture\n",
        "!poetry install"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KreN_oI7D5jZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r3qZu1h7AL_V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "from src import loss\n",
        "from src import model\n",
        "from src import task\n",
        "\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For developoment. Enables making changes to modules without restarting the runtime.\n",
        "%%capture\n",
        "import importlib\n",
        "importlib.reload(loss)\n",
        "importlib.reload(model)\n",
        "importlib.reload(task)"
      ],
      "metadata": {
        "id": "WFeYoDdvMWFK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/grokking_demo.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(pathlib.Path(PTH_LOCATION).parent, exist_ok=True)"
      ],
      "metadata": {
        "id": "wLJlE2DOTggn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "2UdsQtqPLZgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\"\n",
        "\n",
        "P=113\n",
        "DATA_SEED = 598\n",
        "TRAINING_FRACTION = 0.3\n",
        "\n",
        "# Optimizer config\n",
        "LR = 1e-3\n",
        "WD = 1.0 # Very large, makes grokking happen faster, encouarges a simple model\n",
        "BETAS = (0.9, 0.98)\n",
        "\n",
        "NUM_EPOCHS = 25_000\n",
        "CHECKPOINT_EVERY = 100\n",
        "EARLY_STOPPING_LOSS = 1e-6\n",
        "\n",
        "PLOTLY_TEMPLATE = \"plotly_dark\""
      ],
      "metadata": {
        "id": "QRyQljZvKyux"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "NsC_HeVRM65S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hooked_model = model.get_hooked_transformer(p=P, device=DEVICE)\n",
        "# Disable the biases, as we don't need them for this task and it makes things easier to interpret.\n",
        "for name, param in hooked_model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False"
      ],
      "metadata": {
        "id": "lox7gR2QKcST"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the task"
      ],
      "metadata": {
        "id": "Jo6GFKq7M89i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels, test_data, test_labels = task.make_data_and_labels(p=P, device=DEVICE, data_seed=DATA_SEED, training_fraction=TRAINING_FRACTION)"
      ],
      "metadata": {
        "id": "xa_Svf1aKlqs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Optimizer"
      ],
      "metadata": {
        "id": "h0-KUgN-M_nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(hooked_model.parameters(), lr=LR, weight_decay=WD, betas=BETAS)"
      ],
      "metadata": {
        "id": "sDw_tOsGNBnn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "ROyThpK7P2Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses: list[float] = []\n",
        "test_losses: list [float] = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs: list[int] = []\n",
        "\n",
        "for epoch in (pbar := tqdm.trange(NUM_EPOCHS, unit=\" epoch\")):\n",
        "    train_logits = hooked_model(train_data)\n",
        "    train_loss = loss.mean_log_prob_loss(train_logits, train_labels)\n",
        "    train_loss.backward()\n",
        "    train_losses.append(train_loss.item())\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      test_logits = hooked_model(test_data)\n",
        "      test_loss = loss.mean_log_prob_loss(test_logits, test_labels)\n",
        "      test_losses.append(test_loss.item())\n",
        "\n",
        "    if ((epoch+1) % CHECKPOINT_EVERY)==0:\n",
        "      checkpoint_epochs.append(epoch)\n",
        "      model_checkpoints.append(copy.deepcopy(hooked_model.state_dict()))\n",
        "      pbar.set_description(f\"Train Loss {train_losses[-1]:.4f}, Test Loss {test_losses[-1]:.4f}\")\n",
        "\n",
        "    if test_losses[-1] < EARLY_STOPPING_LOSS:\n",
        "      print(f\"\\nEarly stopping after {epoch} epochs.\")\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yqD31IaP43a",
        "outputId": "41a8d8a3-68bf-43e5-a4aa-683f0deb3808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss 0.0000, Test Loss 27.5485:  14%|█▎        | 3392/25000 [01:24<08:17, 43.45 epoch/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(\n",
        "    {\n",
        "        \"model\":hooked_model.state_dict(),\n",
        "        \"config\": hooked_model.cfg,\n",
        "        \"checkpoints\": model_checkpoints,\n",
        "        \"checkpoint_epochs\": checkpoint_epochs,\n",
        "        \"test_losses\": test_losses,\n",
        "        \"train_losses\": train_losses,\n",
        "        # \"train_indices\": train_indices,\n",
        "        # \"test_indices\": test_indices,\n",
        "    },\n",
        "    PTH_LOCATION)"
      ],
      "metadata": {
        "id": "ELGTDfU-TNOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "## Show Model Training Statistics, Check that it groks!"
      ],
      "metadata": {
        "id": "fTahlBd8WUAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(0, len(train_losses), 100)\n",
        "y1 = train_losses[::100]\n",
        "y2 = test_losses[::100]\n",
        "\n",
        "fig = go.Figure(\n",
        "    data = [\n",
        "        go.Scatter(x=x, y=y1, name=\"train\"),\n",
        "        go.Scatter(x=x, y=y2, name=\"test\"),\n",
        "    ],\n",
        "    layout = {\n",
        "        \"xaxis\": {\"title\": \"Epoch\"},\n",
        "        \"yaxis\": {\"title\": \"Loss\", \"type\": \"log\"},\n",
        "        \"title\": f\"Training Curve for Base {P} Modular Addition\",\n",
        "        \"template\": PLOTLY_TEMPLATE,\n",
        "    }\n",
        ")\n",
        "fig\n"
      ],
      "metadata": {
        "id": "V4TXT3I9V_uo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}